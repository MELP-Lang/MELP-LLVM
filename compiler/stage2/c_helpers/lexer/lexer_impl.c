/* MELP Stage 2 - Lexer Implementation
 * Generated by: YZ_02 (Lexer Specialist)
 * Date: 15 Ocak 2026
 * Phase: 2.0 - Lexer Implementation (Task 2.3)
 * 
 * This file implements the lexical analyzer for PMLP0 syntax.
 * 
 * Architecture:
 * - Scanner state machine for character-by-character processing
 * - Token recognition via lookahead
 * - Line/column tracking for error reporting
 * - Simple memory management (fixed-size token array, reallocated if needed)
 * 
 * Design Principles (AUTONOMOUS):
 * - Single responsibility: ONLY tokenization
 * - NO parser logic
 * - Standalone module (peer to parser)
 * - ~1000 lines (natural size, not artificially limited)
 */

/* For strdup() on POSIX systems */
#define _POSIX_C_SOURCE 200809L

#include "lexer_impl.h"
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <ctype.h>

/* ============================================================================
 * SCANNER STATE
 * ============================================================================ */

/* Scanner maintains position in source string and tracks line/column */
typedef struct {
    const char* start;      /* Start of current token */
    const char* current;    /* Current character position */
    int line;               /* Current line (1-based) */
    int column;             /* Current column (1-based) */
} Scanner;

/* Global scanner (simplifies function signatures) */
static Scanner scanner;

/* ============================================================================
 * CHARACTER CLASSIFICATION
 * ============================================================================ */

int is_digit(char c) {
    return c >= '0' && c <= '9';
}

int is_alpha(char c) {
    return (c >= 'a' && c <= 'z') ||
           (c >= 'A' && c <= 'Z') ||
           (c == '_');
}

int is_alphanumeric(char c) {
    return is_alpha(c) || is_digit(c);
}

int is_whitespace(char c) {
    return c == ' ' || c == '\t' || c == '\r';
}

/* ============================================================================
 * SCANNER UTILITIES
 * ============================================================================ */

/* Check if at end of source */
static int is_at_end() {
    return *scanner.current == '\0';
}

/* Advance scanner and return previous character */
static char advance() {
    char c = *scanner.current;
    scanner.current++;
    scanner.column++;
    return c;
}

/* Peek at current character without advancing */
static char peek() {
    return *scanner.current;
}

/* Peek at next character (lookahead 1) */
static char peek_next() __attribute__((unused));
static char peek_next() {
    if (is_at_end()) return '\0';
    return scanner.current[1];
}

/* Check if current character matches expected, advance if so */
static int match(char expected) {
    if (is_at_end()) return 0;
    if (*scanner.current != expected) return 0;
    advance();
    return 1;
}

/* Skip whitespace (but NOT newlines - they're significant!) */
static void skip_whitespace() {
    while (!is_at_end()) {
        char c = peek();
        if (is_whitespace(c)) {
            advance();
        } else {
            break;
        }
    }
}

/* ============================================================================
 * TOKEN CONSTRUCTION
 * ============================================================================ */

Token make_token(TokenType type, const char* lexeme, int lexeme_length, int line, int column) {
    Token token;
    token.type = type;
    token.lexeme = lexeme;
    token.lexeme_length = lexeme_length;
    token.line = line;
    token.column = column;
    token.value.int_value = 0;  /* Default */
    return token;
}

Token make_error_token(const char* message, int line, int column) {
    Token token;
    token.type = TOKEN_ERROR;
    token.lexeme = message;
    token.lexeme_length = strlen(message);
    token.line = line;
    token.column = column;
    token.value.str_value = strdup(message);  /* Copy error message */
    return token;
}

/* Create token from scanner's current position */
static Token make_token_from_scanner(TokenType type) {
    int length = (int)(scanner.current - scanner.start);
    int col = scanner.column - length;
    return make_token(type, scanner.start, length, scanner.line, col);
}

/* ============================================================================
 * KEYWORD RECOGNITION
 * ============================================================================ */

/* Check if identifier matches keyword */
static TokenType check_keyword(int start_offset, int length, const char* rest, TokenType type) {
    int total_length = (int)(scanner.current - scanner.start);
    if (total_length == start_offset + length &&
        memcmp(scanner.start + start_offset, rest, length) == 0) {
        return type;
    }
    return TOKEN_IDENTIFIER;
}

/* Identify keyword or return TOKEN_IDENTIFIER
 * 
 * Keywords are checked by length and first character for efficiency.
 * This implements a simple trie-like structure.
 */
static TokenType identifier_type() {
    /* Get first character */
    char first = scanner.start[0];
    int length = (int)(scanner.current - scanner.start);
    
    switch (first) {
        case 'a':
            if (length == 2) return check_keyword(1, 1, "s", TOKEN_AS);
            if (length == 3) return check_keyword(1, 2, "nd", TOKEN_AND);
            break;
        case 'b':
            if (length == 7) return check_keyword(1, 6, "oolean", TOKEN_BOOLEAN);
            break;
        case 'e':
            if (length == 4) return check_keyword(1, 3, "lse", TOKEN_ELSE);
            if (length == 6) return check_keyword(1, 5, "nd_if", TOKEN_END_IF);
            if (length == 7) return check_keyword(1, 6, "lse_if", TOKEN_ELSE_IF);
            if (length == 9) return check_keyword(1, 8, "nd_while", TOKEN_END_WHILE);
            if (length == 12) return check_keyword(1, 11, "nd_function", TOKEN_END_FUNCTION);
            break;
        case 'f':
            if (length == 5) return check_keyword(1, 4, "alse", TOKEN_FALSE);
            if (length == 8) return check_keyword(1, 7, "unction", TOKEN_FUNCTION);
            break;
        case 'i':
            if (length == 2) return check_keyword(1, 1, "f", TOKEN_IF);
            break;
        case 'm':
            if (length == 3) return check_keyword(1, 2, "od", TOKEN_MOD);
            break;
        case 'n':
            if (length == 3) {
                if (memcmp(scanner.start + 1, "ot", 2) == 0) return TOKEN_NOT;
            }
            if (length == 7) return check_keyword(1, 6, "umeric", TOKEN_NUMERIC);
            break;
        case 'o':
            if (length == 2) return check_keyword(1, 1, "r", TOKEN_OR);
            break;
        case 'r':
            if (length == 6) return check_keyword(1, 5, "eturn", TOKEN_RETURN);
            break;
        case 't':
            if (length == 4) {
                if (memcmp(scanner.start + 1, "hen", 3) == 0) return TOKEN_THEN;
                if (memcmp(scanner.start + 1, "rue", 3) == 0) return TOKEN_TRUE;
            }
            break;
        case 'v':
            if (length == 3) return check_keyword(1, 2, "ar", TOKEN_VAR);
            break;
        case 'w':
            if (length == 5) return check_keyword(1, 4, "hile", TOKEN_WHILE);
            break;
    }
    
    return TOKEN_IDENTIFIER;
}

/* ============================================================================
 * TOKEN SCANNING
 * ============================================================================ */

/* Scan a number literal (integer only for Stage 2) */
static Token scan_number() {
    /* Consume all digits */
    while (is_digit(peek())) {
        advance();
    }
    
    Token token = make_token_from_scanner(TOKEN_NUMBER);
    
    /* Parse integer value */
    char* endptr;
    token.value.int_value = strtoll(scanner.start, &endptr, 10);
    
    return token;
}

/* Scan an identifier or keyword */
static Token scan_identifier() {
    /* Consume all alphanumeric characters */
    while (is_alphanumeric(peek())) {
        advance();
    }
    
    /* Check if it's a keyword */
    TokenType type = identifier_type();
    return make_token_from_scanner(type);
}

/* Scan a string literal "..." (minimal support) */
static Token scan_string() {
    /* Opening quote already consumed */
    
    /* Scan until closing quote or end of line */
    while (!is_at_end() && peek() != '"' && peek() != '\n') {
        advance();
    }
    
    /* Check for unterminated string */
    if (is_at_end() || peek() == '\n') {
        return make_error_token("Unterminated string literal", scanner.line, scanner.column);
    }
    
    /* Consume closing quote */
    advance();
    
    Token token = make_token_from_scanner(TOKEN_STRING);
    
    /* Extract string content (without quotes) */
    int content_length = token.lexeme_length - 2;  /* Exclude quotes */
    char* str_content = malloc(content_length + 1);
    memcpy(str_content, token.lexeme + 1, content_length);
    str_content[content_length] = '\0';
    token.value.str_value = str_content;
    
    return token;
}

/* Scan a comment (-- to end of line) */
static Token scan_comment() {
    /* Consume until newline or EOF */
    while (!is_at_end() && peek() != '\n') {
        advance();
    }
    
    return make_token_from_scanner(TOKEN_COMMENT);
}

/* Scan next token from current position
 * 
 * Main token recognition logic.
 * Returns one token per call.
 */
static Token scan_token() {
    /* Skip whitespace */
    skip_whitespace();
    
    /* Mark start of token */
    scanner.start = scanner.current;
    
    /* Check for end of input */
    if (is_at_end()) {
        return make_token_from_scanner(TOKEN_EOF);
    }
    
    /* Get next character */
    char c = advance();
    
    /* Identifiers and keywords */
    if (is_alpha(c)) {
        return scan_identifier();
    }
    
    /* Numbers */
    if (is_digit(c)) {
        return scan_number();
    }
    
    /* Multi-character and single-character tokens */
    switch (c) {
        /* Newline (statement separator) */
        case '\n': {
            Token token = make_token_from_scanner(TOKEN_NEWLINE);
            scanner.line++;
            scanner.column = 1;
            return token;
        }
        
        /* Parentheses */
        case '(': return make_token_from_scanner(TOKEN_LEFT_PAREN);
        case ')': return make_token_from_scanner(TOKEN_RIGHT_PAREN);
        
        /* Brackets */
        case '[': return make_token_from_scanner(TOKEN_LEFT_BRACKET);
        case ']': return make_token_from_scanner(TOKEN_RIGHT_BRACKET);
        
        /* Punctuation */
        case ';': return make_token_from_scanner(TOKEN_SEMICOLON);
        case ',': return make_token_from_scanner(TOKEN_COMMA);
        
        /* Arithmetic operators */
        case '+': return make_token_from_scanner(TOKEN_PLUS);
        case '*': return make_token_from_scanner(TOKEN_STAR);
        case '/': return make_token_from_scanner(TOKEN_SLASH);
        
        /* Minus or comment */
        case '-':
            if (match('-')) {
                /* Comment: -- to end of line */
                return scan_comment();
            }
            return make_token_from_scanner(TOKEN_MINUS);
        
        /* Assignment or equality */
        case '=':
            if (match('=')) {
                return make_token_from_scanner(TOKEN_EQUAL_EQUAL);
            }
            return make_token_from_scanner(TOKEN_EQUAL);
        
        /* Inequality */
        case '!':
            if (match('=')) {
                return make_token_from_scanner(TOKEN_NOT_EQUAL);
            }
            /* Standalone ! is error (use 'not' keyword) */
            return make_error_token("Unexpected character '!' (use 'not' for logical NOT)", 
                                   scanner.line, scanner.column - 1);
        
        /* Less than or less equal */
        case '<':
            if (match('=')) {
                return make_token_from_scanner(TOKEN_LESS_EQUAL);
            }
            return make_token_from_scanner(TOKEN_LESS);
        
        /* Greater than or greater equal */
        case '>':
            if (match('=')) {
                return make_token_from_scanner(TOKEN_GREATER_EQUAL);
            }
            return make_token_from_scanner(TOKEN_GREATER);
        
        /* String literal */
        case '"':
            return scan_string();
        
        /* Unknown character */
        default: {
            char error_msg[100];
            snprintf(error_msg, sizeof(error_msg), 
                    "Unexpected character '%c' (ASCII %d)", c, (int)c);
            return make_error_token(error_msg, scanner.line, scanner.column - 1);
        }
    }
}

/* ============================================================================
 * MAIN TOKENIZATION API
 * ============================================================================ */

Token* tokenize(const char* source, int* out_token_count) {
    /* Initialize scanner */
    scanner.start = source;
    scanner.current = source;
    scanner.line = 1;
    scanner.column = 1;
    
    /* Initial token array (will grow if needed) */
    int capacity = 256;
    int count = 0;
    Token* tokens = malloc(sizeof(Token) * capacity);
    
    if (!tokens) {
        *out_token_count = 0;
        return NULL;
    }
    
    /* Scan all tokens */
    while (!is_at_end()) {
        Token token = scan_token();
        
        /* Skip comment tokens (don't add to output) */
        if (token.type == TOKEN_COMMENT) {
            continue;
        }
        
        /* Grow array if needed */
        if (count >= capacity) {
            capacity *= 2;
            Token* new_tokens = realloc(tokens, sizeof(Token) * capacity);
            if (!new_tokens) {
                free_tokens(tokens, count);
                *out_token_count = 0;
                return NULL;
            }
            tokens = new_tokens;
        }
        
        /* Add token */
        tokens[count++] = token;
        
        /* Stop at EOF */
        if (token.type == TOKEN_EOF) {
            break;
        }
    }
    
    /* Ensure EOF token is present */
    if (count == 0 || tokens[count - 1].type != TOKEN_EOF) {
        if (count >= capacity) {
            capacity++;
            Token* new_tokens = realloc(tokens, sizeof(Token) * capacity);
            if (!new_tokens) {
                free_tokens(tokens, count);
                *out_token_count = 0;
                return NULL;
            }
            tokens = new_tokens;
        }
        tokens[count++] = make_token(TOKEN_EOF, "", 0, scanner.line, scanner.column);
    }
    
    *out_token_count = count;
    return tokens;
}

void free_tokens(Token* tokens, int count) {
    if (!tokens) return;
    
    /* Free allocated strings in tokens */
    for (int i = 0; i < count; i++) {
        if (tokens[i].type == TOKEN_STRING || 
            tokens[i].type == TOKEN_ERROR ||
            tokens[i].type == TOKEN_IDENTIFIER) {
            /* Check if str_value was allocated */
            if (tokens[i].value.str_value != NULL && 
                tokens[i].value.str_value != tokens[i].lexeme) {
                free(tokens[i].value.str_value);
            }
        }
    }
    
    /* Free token array */
    free(tokens);
}

/* ============================================================================
 * UTILITY FUNCTIONS
 * ============================================================================ */

const char* token_type_name(TokenType type) {
    switch (type) {
        case TOKEN_NUMBER: return "NUMBER";
        case TOKEN_IDENTIFIER: return "IDENTIFIER";
        case TOKEN_TRUE: return "TRUE";
        case TOKEN_FALSE: return "FALSE";
        case TOKEN_STRING: return "STRING";
        case TOKEN_FUNCTION: return "FUNCTION";
        case TOKEN_END_FUNCTION: return "END_FUNCTION";
        case TOKEN_AS: return "AS";
        case TOKEN_RETURN: return "RETURN";
        case TOKEN_IF: return "IF";
        case TOKEN_THEN: return "THEN";
        case TOKEN_ELSE: return "ELSE";
        case TOKEN_ELSE_IF: return "ELSE_IF";
        case TOKEN_END_IF: return "END_IF";
        case TOKEN_WHILE: return "WHILE";
        case TOKEN_END_WHILE: return "END_WHILE";
        case TOKEN_VAR: return "VAR";
        case TOKEN_NUMERIC: return "NUMERIC";
        case TOKEN_BOOLEAN: return "BOOLEAN";
        case TOKEN_PLUS: return "+";
        case TOKEN_MINUS: return "-";
        case TOKEN_STAR: return "*";
        case TOKEN_SLASH: return "/";
        case TOKEN_MOD: return "MOD";
        case TOKEN_EQUAL: return "=";
        case TOKEN_EQUAL_EQUAL: return "==";
        case TOKEN_NOT_EQUAL: return "!=";
        case TOKEN_LESS: return "<";
        case TOKEN_LESS_EQUAL: return "<=";
        case TOKEN_GREATER: return ">";
        case TOKEN_GREATER_EQUAL: return ">=";
        case TOKEN_AND: return "AND";
        case TOKEN_OR: return "OR";
        case TOKEN_NOT: return "NOT";
        case TOKEN_LEFT_PAREN: return "(";
        case TOKEN_RIGHT_PAREN: return ")";
        case TOKEN_LEFT_BRACKET: return "[";
        case TOKEN_RIGHT_BRACKET: return "]";
        case TOKEN_SEMICOLON: return ";";
        case TOKEN_COMMA: return ",";
        case TOKEN_NEWLINE: return "NEWLINE";
        case TOKEN_COMMENT: return "COMMENT";
        case TOKEN_EOF: return "EOF";
        case TOKEN_ERROR: return "ERROR";
        default: return "UNKNOWN";
    }
}
